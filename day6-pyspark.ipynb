{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cd98c1f-4df6-452b-a459-ea3de326357e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Import required functions\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType,ArrayType,MapType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder.appName(\"create_df_with_orc\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2bc2217-f796-4f63-8278-9ddc9c1634c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    James|   Smith|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|   Robert|Williams|    USA|   CA|\n|    Maria|   Jones|    USA|   FL|\n|     Sira|   Jones|  Nepal|   FL|\n+---------+--------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#Sample Data set\n",
    "all_data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\"),\n",
    "    (\"Sira\",\"Jones\",\"Nepal\",\"FL\")\n",
    "  ]\n",
    "#Create schema to pass while creating DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"firstname\", StringType(), True),\n",
    "    StructField(\"lastname\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True), \n",
    "    StructField(\"state\", StringType(), True) \n",
    "    ])\n",
    "#Create Dataframe    \n",
    "all_data_df = spark.createDataFrame(all_data, schema)\n",
    "all_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b06ae5-0973-444f-8690-5ae7e8d67bd3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_data_df.write.option(\"header\",True) \\\n",
    "        .orc(\"/FileStore/tables/junee_orc_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad29537-6533-4a07-91bc-dd14e3b3fa0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- country: string (nullable = true)\n |-- state: string (nullable = true)\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|   Robert|Williams|    USA|   CA|\n|    James|   Smith|    USA|   CA|\n+---------+--------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "all_data_df_orc = spark.read.orc(\"/FileStore/tables/junee_orc_file\").where(col('state')=='CA')\n",
    "all_data_df_orc.printSchema()\n",
    "all_data_df_orc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "898d00b2-a388-448b-a0dd-a391c0cc889d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Used PartitionBy to partition interms of country\n",
    "all_data_df.write.partitionBy(\"country\").mode(\"overwrite\").orc(\"/FileStore/tables/junee_orc_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e857bc0d-4987-452d-8f37-0a4588944377",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_data_df.write.option(\"header\",True) \\\n",
    "        .parquet(\"/FileStore/tables/june_parquet_files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "599f19b7-388e-47c6-92ec-ffe93b052c2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- firstname: string (nullable = true)\n |-- lastname: string (nullable = true)\n |-- country: string (nullable = true)\n |-- state: string (nullable = true)\n\n+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|    Maria|   Jones|    USA|   FL|\n|     Sira|   Jones|  Nepal|   FL|\n|   Robert|Williams|    USA|   CA|\n|  Michael|    Rose|    USA|   NY|\n|    James|   Smith|    USA|   CA|\n+---------+--------+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "all_data_parquet = spark.read.parquet(\"/FileStore/tables/june_parquet_files\")\n",
    "all_data_parquet.printSchema()\n",
    "all_data_parquet.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ba905a7-76e4-4cf8-af5a-098280bf9ec3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the .data file into a DataFrame\n",
    "read_data = spark.read.format(\"text\") \\\n",
    "             .option(\"delimiter\", \",\") \\\n",
    "             .load(\"/FileStore/tables/iris.data\")\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28fbdf39-e5c9-4a53-a4b2-da031939b48f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#get data from the link and add url\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "from pyspark import SparkFiles\n",
    "spark.sparkContext.addFile(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a512e5b6-e5e5-4b10-8bbc-6e7c1d924fb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- 5.1: double (nullable = true)\n |-- 3.5: double (nullable = true)\n |-- 1.4: double (nullable = true)\n |-- 0.2: double (nullable = true)\n |-- Iris-setosa: string (nullable = true)\n\n+---+---+---+---+-----------+\n|5.1|3.5|1.4|0.2|Iris-setosa|\n+---+---+---+---+-----------+\n|4.9|3.0|1.4|0.2|Iris-setosa|\n|4.7|3.2|1.3|0.2|Iris-setosa|\n|4.6|3.1|1.5|0.2|Iris-setosa|\n|5.0|3.6|1.4|0.2|Iris-setosa|\n|5.4|3.9|1.7|0.4|Iris-setosa|\n|4.6|3.4|1.4|0.3|Iris-setosa|\n|5.0|3.4|1.5|0.2|Iris-setosa|\n|4.4|2.9|1.4|0.2|Iris-setosa|\n|4.9|3.1|1.5|0.1|Iris-setosa|\n|5.4|3.7|1.5|0.2|Iris-setosa|\n|4.8|3.4|1.6|0.2|Iris-setosa|\n|4.8|3.0|1.4|0.1|Iris-setosa|\n|4.3|3.0|1.1|0.1|Iris-setosa|\n|5.8|4.0|1.2|0.2|Iris-setosa|\n|5.7|4.4|1.5|0.4|Iris-setosa|\n|5.4|3.9|1.3|0.4|Iris-setosa|\n|5.1|3.5|1.4|0.3|Iris-setosa|\n|5.7|3.8|1.7|0.3|Iris-setosa|\n|5.1|3.8|1.5|0.3|Iris-setosa|\n|5.4|3.4|1.7|0.2|Iris-setosa|\n+---+---+---+---+-----------+\nonly showing top 20 rows\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "\u001B[0;32m<command-2521248266669753>\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[0monlinedata_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprintSchema\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[0monlinedata_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m----> 5\u001B[0;31m \u001B[0monlinedata_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n",
       "\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m   2072\u001B[0m         \"\"\"\n",
       "\u001B[1;32m   2073\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 2074\u001B[0;31m             raise AttributeError(\n",
       "\u001B[0m\u001B[1;32m   2075\u001B[0m                 \u001B[0;34m\"'%s' object has no attribute '%s'\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   2076\u001B[0m             )\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'nunique'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-2521248266669753>\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0monlinedata_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprintSchema\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0monlinedata_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0monlinedata_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     47\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 48\u001B[0;31m                 \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     49\u001B[0m                 logger.log_success(\n\u001B[1;32m     50\u001B[0m                     \u001B[0mmodule_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclass_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mperf_counter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   2072\u001B[0m         \"\"\"\n\u001B[1;32m   2073\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2074\u001B[0;31m             raise AttributeError(\n\u001B[0m\u001B[1;32m   2075\u001B[0m                 \u001B[0;34m\"'%s' object has no attribute '%s'\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2076\u001B[0m             )\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'nunique'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'DataFrame' object has no attribute 'nunique'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read file and show it schema\n",
    "onlinedata_df = spark.read.csv(\"file://\"+SparkFiles.get(\"iris.data\"), header=True, inferSchema= True)\n",
    "onlinedata_df.printSchema()\n",
    "onlinedata_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1de976b-7ed3-4a6d-a9b4-ccca00d1d8d0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_file = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "rdd = spark.sparkContext.textFile(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "472124d4-95e2-487b-b1e1-fb0ac9320ca6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+\n| id|           address|state|\n+---+------------------+-----+\n|  1|  14851 Jeffrey Rd|   DE|\n|  2|43421 Margarita St|   NY|\n|  3|  13111 Siemon Ave|   CA|\n+---+------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#Create Dataframe from following and replace Rd with Road\n",
    "address = [(1,\"14851 Jeffrey Rd\",\"DE\"),\n",
    "    (2,\"43421 Margarita St\",\"NY\"),\n",
    "    (3,\"13111 Siemon Ave\",\"CA\")]\n",
    "    \n",
    "Columns = ['id', 'address','state']\n",
    "#Create Dataframe from given data and column\n",
    "address_df = spark.createDataFrame(address, Columns)\n",
    "address_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9d9d755-2aed-4a86-9f9c-b896ddb22f99",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+\n| id|           address|state|\n+---+------------------+-----+\n|  1|14851 Jeffrey Road|   DE|\n|  2|43421 Margarita St|   NY|\n|  3|  13111 Siemon Ave|   CA|\n+---+------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#Import regexp_replace to replace a column value with a string\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "# Replace \"Rd\" with \"Road\" in the \"address\" column\n",
    "replace_df = address_df.withColumn(\"address\", regexp_replace(col(\"address\"), \"Rd\", \"Road\"))\n",
    "replace_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8587297-c876-4a7b-9ea3-a9730a788fc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+-----+------------------+\n| id|           address|state|    address_change|\n+---+------------------+-----+------------------+\n|  1|  14851 Jeffrey Rd|   DE|14851 Jeffrey Road|\n|  2|43421 Margarita St|   NY|43421 Margarita St|\n|  3|  13111 Siemon Ave|   CA|  13111 Siemon Ave|\n+---+------------------+-----+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "replace_df = address_df.withColumn(\"address_change\", regexp_replace(col(\"address\"), \"Rd\", \"Road\"))\n",
    "replace_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b6f549a-44c0-44b7-be14-1944cd051797",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal-length</th>\n      <th>sepal-width</th>\n      <th>petal-length</th>\n      <th>petal-width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>3.5</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>Iris-setosa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>6.3</td>\n      <td>2.5</td>\n      <td>5.0</td>\n      <td>1.9</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.0</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>6.2</td>\n      <td>3.4</td>\n      <td>5.4</td>\n      <td>2.3</td>\n      <td>Iris-virginica</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>5.9</td>\n      <td>3.0</td>\n      <td>5.1</td>\n      <td>1.8</td>\n      <td>Iris-virginica</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 5 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get data from the link and add url\n",
    "import pandas as pd\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "col_names =['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'species']\n",
    "iris_dataset = pd.read_csv(url, names=col_names)\n",
    "iris_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecf270f0-1508-45bd-b78a-36fbbffd01c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+-------------------+\n|5.1|3.5|1.4|0.2|Iris-setosa|              class|\n+---+---+---+---+-----------+-------------------+\n|4.9|3.0|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.7|3.2|1.3|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.6|3.1|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.0|3.6|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.9|1.7|0.4|Iris-setosa|Iris-Dataset-setosa|\n|4.6|3.4|1.4|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.0|3.4|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.4|2.9|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.9|3.1|1.5|0.1|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.7|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.8|3.4|1.6|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.8|3.0|1.4|0.1|Iris-setosa|Iris-Dataset-setosa|\n|4.3|3.0|1.1|0.1|Iris-setosa|Iris-Dataset-setosa|\n|5.8|4.0|1.2|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.7|4.4|1.5|0.4|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.9|1.3|0.4|Iris-setosa|Iris-Dataset-setosa|\n|5.1|3.5|1.4|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.7|3.8|1.7|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.1|3.8|1.5|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.4|1.7|0.2|Iris-setosa|Iris-Dataset-setosa|\n+---+---+---+---+-----------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#replace Iris with Iris-Dataset in column Iris-setosa\n",
    "onlinedata_df1=onlinedata_df.withColumn(\"class\", regexp_replace(\"Iris-setosa\", \"Iris\", \"Iris-Dataset\"))\n",
    "onlinedata_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f1a4204-3f41-405a-a32e-543904827133",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+-------------------+\n|5.1|3.5|1.4|0.2|Iris-setosa|              class|\n+---+---+---+---+-----------+-------------------+\n|4.9|3.0|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.7|3.2|1.3|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.6|3.1|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.0|3.6|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.9|1.7|0.4|Iris-setosa|Iris-Dataset-setosa|\n|4.6|3.4|1.4|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.0|3.4|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.4|2.9|1.4|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.9|3.1|1.5|0.1|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.7|1.5|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.8|3.4|1.6|0.2|Iris-setosa|Iris-Dataset-setosa|\n|4.8|3.0|1.4|0.1|Iris-setosa|Iris-Dataset-setosa|\n|4.3|3.0|1.1|0.1|Iris-setosa|Iris-Dataset-setosa|\n|5.8|4.0|1.2|0.2|Iris-setosa|Iris-Dataset-setosa|\n|5.7|4.4|1.5|0.4|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.9|1.3|0.4|Iris-setosa|Iris-Dataset-setosa|\n|5.1|3.5|1.4|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.7|3.8|1.7|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.1|3.8|1.5|0.3|Iris-setosa|Iris-Dataset-setosa|\n|5.4|3.4|1.7|0.2|Iris-setosa|Iris-Dataset-setosa|\n+---+---+---+---+-----------+-------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74264702-0b37-4c44-8573-d0d5d9d26dda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Name: struct (nullable = true)\n |    |-- Fir: string (nullable = true)\n |    |-- Mi: string (nullable = true)\n |    |-- La: string (nullable = true)\n |-- languages: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+------------------+-----+------+\n|Name                  |languages         |state|gender|\n+----------------------+------------------+-----+------+\n|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n|{Anna, Rose, }        |[Spark, Java, C++]|NY   |F     |\n|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n|{Maria, Anne, Jones}  |[CSharp, VB]      |NY   |M     |\n|{Jen, Mary, Brown}    |[CSharp, VB]      |NY   |M     |\n|{Mike, Mary, Williams}|[Python, VB]      |OH   |M     |\n+----------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"OH\",\"M\")\n",
    " ]\n",
    "schema = StructType([\n",
    "     StructField('Name', StructType([\n",
    "        StructField('Fir', StringType(), True),\n",
    "        StructField('Mi', StringType(), True),\n",
    "        StructField('La', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    " ])\n",
    "#Create Dataframe with given data and schema\n",
    "new_df = spark.createDataFrame(data,  schema)\n",
    "new_df.printSchema()\n",
    "new_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f1e2247-3595-467f-8087-16c3a961be6f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n| {Julia, , Williams}|      [CSharp, VB]|   OH|     F|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#1.Task- Give me only those rows which has State OH\n",
    "#Using filter to filter the Datafreame that contains OH\n",
    "df_with_state_OH = new_df.filter(new_df.state == 'OH')\n",
    "df_with_state_OH.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "216dd7d9-b0ad-440e-b80e-ccfe4241f781",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                Name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#2.Task - Give me only those rows which does not have state OH\n",
    "df_without_state_OH = new_df.filter(new_df.state != 'OH')\n",
    "df_without_state_OH.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25058dda-003a-4c1f-bfc5-345cd7e520d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                Name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#3.Task- Give me those people whose gender is M\n",
    "df_with_gender_M = new_df.filter(new_df.gender == 'M')\n",
    "df_with_gender_M.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1e51b1-bef4-4b89-80fb-feff45964ecd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[117]: Column<'Name'>"
     ]
    }
   ],
   "source": [
    "new_df.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2fa646f-f5d9-4692-b70a-102a90bd6760",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                Name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Import length to check the length of string data\n",
    "from pyspark.sql.functions import length\n",
    "\n",
    "result = new_df.filter(length(new_df.Name.Mi) > 0)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3edb33ee-1bbc-49a7-8611-f49c7c6e7ff1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                Name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   OH|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#just check if Middle name is empty or not\n",
    "result1 = new_df.filter(new_df.Name.Mi != \"\")\n",
    "result1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7647d766-b68f-4255-9fae-bf52fce1953b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|length(state)|\n+-------------+\n|            2|\n|            2|\n|            2|\n|            2|\n|            2|\n|            2|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "new_df.select(F.length(\"state\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82daf5e6-d725-40ef-af67-1d532df501cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                Name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n| {Julia, , Williams}|      [CSharp, VB]|   DE|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n|{Mike, Mary, Will...|      [Python, VB]|   CA|     M|\n|{Mike, Mary, Will...|      [Python, VB]| ACCA|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "new_data = [\n",
    "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
    "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
    "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"DE\",\"F\"),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"CA\",\"M\"),\n",
    "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"ACCA\",\"M\"),\n",
    " ]\n",
    "new_schema = StructType([\n",
    "     StructField('Name', StructType([\n",
    "        StructField('Fir', StringType(), True),\n",
    "        StructField('Mi', StringType(), True),\n",
    "        StructField('La', StringType(), True)\n",
    "     ])),\n",
    "     StructField('languages', ArrayType(StringType()), True),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    " ])\n",
    "#Create Dataframe with given data and schema\n",
    "new_df1 = spark.createDataFrame(new_data,  new_schema)\n",
    "new_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4fd6c2-bb01-4d6c-86c3-55ca7f70ca82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+-----+------+\n|                Name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|    {James, , Smith}|[Java, Scala, C++]|   OH|     M|\n| {Julia, , Williams}|      [CSharp, VB]|   DE|     F|\n|{Mike, Mary, Will...|      [Python, VB]|   CA|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Using filter to filter the Datafreame that contains OH,CA,DE\n",
    "new_df_with_state = new_df1.filter(new_df1.state.isin(['OH', 'CA', 'DE']))\n",
    "new_df_with_state.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b07772-6941-4e01-bd61-1b9fac4cd9de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----+------+\n|Name|languages|state|gender|\n+----+---------+-----+------+\n+----+---------+-----+------+\n\n+--------------------+------------------+-----+------+\n|                Name|         languages|state|gender|\n+--------------------+------------------+-----+------+\n|      {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n|{Maria, Anne, Jones}|      [CSharp, VB]|   NY|     M|\n|  {Jen, Mary, Brown}|      [CSharp, VB]|   NY|     M|\n+--------------------+------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Task 1- I need all the states which starts from H\n",
    "#Use startswith Function to get the element of state that starts with H\n",
    "df_start_with_H = new_df1.filter(new_df1.state.startswith(\"H\"))\n",
    "df_start_with_H.show()\n",
    "\n",
    "#There are no any element starts with H so Lets check for element starts with N\n",
    "df_start_with_H = new_df1.filter(new_df1.state.startswith(\"N\"))\n",
    "df_start_with_H.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e2ed02-3d01-450d-9ed4-40e3c98a5545",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+------+\n|                Name|   languages|state|gender|\n+--------------------+------------+-----+------+\n|{Mike, Mary, Will...|[Python, VB]|   CA|     M|\n+--------------------+------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Task2-  I need all the states Which end A\n",
    "#Use endswith Function to get the element of state that ends with A\n",
    "df_end_with_A  = new_df1.filter(new_df1.state.endswith(\"A\"))\n",
    "df_end_with_A.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a90af57f-51d3-466d-b778-5000c93389f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----+------+\n|                Name|   languages|state|gender|\n+--------------------+------------+-----+------+\n|{Mike, Mary, Will...|[Python, VB]|   CA|     M|\n|{Mike, Mary, Will...|[Python, VB]| ACCA|     M|\n+--------------------+------------+-----+------+\n\n+--------------------+------------+-----+------+\n|                Name|   languages|state|gender|\n+--------------------+------------+-----+------+\n|{Mike, Mary, Will...|[Python, VB]|   CA|     M|\n|{Mike, Mary, Will...|[Python, VB]| ACCA|     M|\n+--------------------+------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Task 3- I need all the states which has C contains\n",
    "#Use Contain Function to check  whether the element of state contain letter C\n",
    "df_containig_C = new_df1.filter(new_df1.state.contains(\"C\"))\n",
    "df_containig_C.show()\n",
    "\n",
    "df_containig_C = new_df1.filter(new_df1.state.contains(\"CA\"))\n",
    "df_containig_C.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb58e92f-aaad-47e5-9cf6-46710a2c5372",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n|5.1|3.5|1.4|0.2|Iris-setosa|\n+---+---+---+---+-----------+\n|4.9|3.0|1.4|0.2|Iris-setosa|\n|4.7|3.2|1.3|0.2|Iris-setosa|\n|4.6|3.1|1.5|0.2|Iris-setosa|\n|5.0|3.6|1.4|0.2|Iris-setosa|\n|5.4|3.9|1.7|0.4|Iris-setosa|\n|4.6|3.4|1.4|0.3|Iris-setosa|\n|5.0|3.4|1.5|0.2|Iris-setosa|\n|4.4|2.9|1.4|0.2|Iris-setosa|\n|4.9|3.1|1.5|0.1|Iris-setosa|\n|5.4|3.7|1.5|0.2|Iris-setosa|\n|4.8|3.4|1.6|0.2|Iris-setosa|\n|4.8|3.0|1.4|0.1|Iris-setosa|\n|4.3|3.0|1.1|0.1|Iris-setosa|\n|5.8|4.0|1.2|0.2|Iris-setosa|\n|5.7|4.4|1.5|0.4|Iris-setosa|\n|5.4|3.9|1.3|0.4|Iris-setosa|\n|5.1|3.5|1.4|0.3|Iris-setosa|\n|5.7|3.8|1.7|0.3|Iris-setosa|\n|5.1|3.8|1.5|0.3|Iris-setosa|\n|5.4|3.4|1.7|0.2|Iris-setosa|\n+---+---+---+---+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "onlinedata_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb8a3b1-23ac-4bb6-8d96-26708a76b89e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+-----------+\n|5.1|3.5|1.4|0.2|Iris-setosa|\n+---+---+---+---+-----------+\n|4.9|3.0|1.4|0.2|Iris-setosa|\n|4.7|3.2|1.3|0.2|Iris-setosa|\n|4.6|3.1|1.5|0.2|Iris-setosa|\n|5.0|3.6|1.4|0.2|Iris-setosa|\n|5.4|3.9|1.7|0.4|Iris-setosa|\n|4.6|3.4|1.4|0.3|Iris-setosa|\n|5.0|3.4|1.5|0.2|Iris-setosa|\n|4.4|2.9|1.4|0.2|Iris-setosa|\n|4.9|3.1|1.5|0.1|Iris-setosa|\n|5.4|3.7|1.5|0.2|Iris-setosa|\n|4.8|3.4|1.6|0.2|Iris-setosa|\n|4.8|3.0|1.4|0.1|Iris-setosa|\n|4.3|3.0|1.1|0.1|Iris-setosa|\n|5.8|4.0|1.2|0.2|Iris-setosa|\n|5.7|4.4|1.5|0.4|Iris-setosa|\n|5.4|3.9|1.3|0.4|Iris-setosa|\n|5.1|3.5|1.4|0.3|Iris-setosa|\n|5.7|3.8|1.7|0.3|Iris-setosa|\n|5.1|3.8|1.5|0.3|Iris-setosa|\n|5.4|3.4|1.7|0.2|Iris-setosa|\n+---+---+---+---+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "onlinedata_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05fddbca-cfc7-4451-970e-04b6963891da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#using withColumnRenamed function to rename one column name mwith new one\n",
    "new_onlinedata_df = onlinedata_df.withColumnRenamed('5.1', 'sepal_length') \\\n",
    "                    .withColumnRenamed('3.5', 'sepal_width') \\\n",
    "                    .withColumnRenamed('1.4', 'petal_length') \\\n",
    "                    .withColumnRenamed('0.2', 'petal_width') \\\n",
    "                    .withColumnRenamed('Iris-setosa', 'species')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1166cf74-fc70-476a-a4ea-c01fe4f3db14",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n|sepal_length|sepal_width|petal_length|petal_width|    species|\n+------------+-----------+------------+-----------+-----------+\n|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n|         5.4|        3.7|         1.5|        0.2|Iris-setosa|\n|         4.8|        3.4|         1.6|        0.2|Iris-setosa|\n|         4.8|        3.0|         1.4|        0.1|Iris-setosa|\n|         4.3|        3.0|         1.1|        0.1|Iris-setosa|\n|         5.8|        4.0|         1.2|        0.2|Iris-setosa|\n|         5.7|        4.4|         1.5|        0.4|Iris-setosa|\n|         5.4|        3.9|         1.3|        0.4|Iris-setosa|\n|         5.1|        3.5|         1.4|        0.3|Iris-setosa|\n|         5.7|        3.8|         1.7|        0.3|Iris-setosa|\n|         5.1|        3.8|         1.5|        0.3|Iris-setosa|\n|         5.4|        3.4|         1.7|        0.2|Iris-setosa|\n+------------+-----------+------------+-----------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#showing new dataframe with new column names replaces\n",
    "new_onlinedata_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eedbbd48-4056-4592-aaa7-f68c316b9372",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+--------------+\n|sepal_length|sepal_width|petal_length|petal_width|       species|\n+------------+-----------+------------+-----------+--------------+\n|         6.3|        3.3|         6.0|        2.5|Iris-virginica|\n|         5.8|        2.7|         5.1|        1.9|Iris-virginica|\n|         7.1|        3.0|         5.9|        2.1|Iris-virginica|\n|         6.3|        2.9|         5.6|        1.8|Iris-virginica|\n|         6.5|        3.0|         5.8|        2.2|Iris-virginica|\n|         7.6|        3.0|         6.6|        2.1|Iris-virginica|\n|         4.9|        2.5|         4.5|        1.7|Iris-virginica|\n|         7.3|        2.9|         6.3|        1.8|Iris-virginica|\n|         6.7|        2.5|         5.8|        1.8|Iris-virginica|\n|         7.2|        3.6|         6.1|        2.5|Iris-virginica|\n|         6.5|        3.2|         5.1|        2.0|Iris-virginica|\n|         6.4|        2.7|         5.3|        1.9|Iris-virginica|\n|         6.8|        3.0|         5.5|        2.1|Iris-virginica|\n|         5.7|        2.5|         5.0|        2.0|Iris-virginica|\n|         5.8|        2.8|         5.1|        2.4|Iris-virginica|\n|         6.4|        3.2|         5.3|        2.3|Iris-virginica|\n|         6.5|        3.0|         5.5|        1.8|Iris-virginica|\n|         7.7|        3.8|         6.7|        2.2|Iris-virginica|\n|         7.7|        2.6|         6.9|        2.3|Iris-virginica|\n|         6.0|        2.2|         5.0|        1.5|Iris-virginica|\n+------------+-----------+------------+-----------+--------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#filter dataframe where element of species is Iris-virginica\n",
    "new_onlinedata_df_virginica = new_onlinedata_df.filter(new_onlinedata_df.species == \"Iris-virginica\")\n",
    "new_onlinedata_df_virginica.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e79bd730-223e-49ab-9d4b-7ceb918f1aef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n|sepal_length|sepal_width|petal_length|petal_width|    species|\n+------------+-----------+------------+-----------+-----------+\n|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n|         5.4|        3.7|         1.5|        0.2|Iris-setosa|\n|         4.8|        3.4|         1.6|        0.2|Iris-setosa|\n|         4.8|        3.0|         1.4|        0.1|Iris-setosa|\n|         4.3|        3.0|         1.1|        0.1|Iris-setosa|\n|         5.8|        4.0|         1.2|        0.2|Iris-setosa|\n|         5.7|        4.4|         1.5|        0.4|Iris-setosa|\n|         5.4|        3.9|         1.3|        0.4|Iris-setosa|\n|         5.1|        3.5|         1.4|        0.3|Iris-setosa|\n|         5.7|        3.8|         1.7|        0.3|Iris-setosa|\n|         5.1|        3.8|         1.5|        0.3|Iris-setosa|\n|         5.4|        3.4|         1.7|        0.2|Iris-setosa|\n+------------+-----------+------------+-----------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "#filter dataframe where element of species is not Iris-virginica\n",
    "new_onlinedata_without_virginica = new_onlinedata_df.filter(new_onlinedata_df.species != \"Iris-virginica\")\n",
    "new_onlinedata_without_virginica.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "536d78d1-7dce-47b9-99e1-055e5273ad92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n|sepal_length|sepal_width|petal_length|petal_width|    species|\n+------------+-----------+------------+-----------+-----------+\n|         5.1|        3.3|         1.7|        0.5|Iris-setosa|\n|         5.0|        3.5|         1.6|        0.6|Iris-setosa|\n+------------+-----------+------------+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#Filter with multiple condition\n",
    "df_multiple_condition = new_onlinedata_df.filter( (new_onlinedata_df.species  == \"Iris-setosa\") & (new_onlinedata_df.petal_width  > 0.4) )\n",
    "df_multiple_condition.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91dc9ec6-2bbd-4bb4-94de-5ed98b03fae8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+---------------+\n|sepal_length|sepal_width|petal_length|petal_width|        species|\n+------------+-----------+------------+-----------+---------------+\n|         5.8|        4.0|         1.2|        0.2|    Iris-setosa|\n|         5.0|        2.0|         3.5|        1.0|Iris-versicolor|\n+------------+-----------+------------+-----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "#Using isin function\n",
    "new_df_with_isin = new_onlinedata_df.filter(new_onlinedata_df.sepal_width.isin(['2.0','4.0']))\n",
    "new_df_with_isin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca258a10-d3b8-4430-856a-320f5ee609bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n|sepal_length|sepal_width|petal_length|petal_width|    species|\n+------------+-----------+------------+-----------+-----------+\n|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n|         5.4|        3.7|         1.5|        0.2|Iris-setosa|\n|         5.8|        4.0|         1.2|        0.2|Iris-setosa|\n|         5.7|        4.4|         1.5|        0.4|Iris-setosa|\n|         5.4|        3.9|         1.3|        0.4|Iris-setosa|\n|         5.1|        3.5|         1.4|        0.3|Iris-setosa|\n|         5.7|        3.8|         1.7|        0.3|Iris-setosa|\n|         5.1|        3.8|         1.5|        0.3|Iris-setosa|\n|         5.4|        3.4|         1.7|        0.2|Iris-setosa|\n|         5.1|        3.7|         1.5|        0.4|Iris-setosa|\n|         5.1|        3.3|         1.7|        0.5|Iris-setosa|\n|         5.0|        3.0|         1.6|        0.2|Iris-setosa|\n|         5.0|        3.4|         1.6|        0.4|Iris-setosa|\n|         5.2|        3.5|         1.5|        0.2|Iris-setosa|\n|         5.2|        3.4|         1.4|        0.2|Iris-setosa|\n|         5.4|        3.4|         1.5|        0.4|Iris-setosa|\n|         5.2|        4.1|         1.5|        0.1|Iris-setosa|\n|         5.5|        4.2|         1.4|        0.2|Iris-setosa|\n+------------+-----------+------------+-----------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Using startswith\n",
    "new_onlinedata_df.filter(new_onlinedata_df.sepal_length.startswith(\"5\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42150bc2-e6f6-4ecb-a194-fccd5997fcd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+---------------+\n|sepal_length|sepal_width|petal_length|petal_width|        species|\n+------------+-----------+------------+-----------+---------------+\n|         5.5|        4.2|         1.4|        0.2|    Iris-setosa|\n|         5.5|        3.5|         1.3|        0.2|    Iris-setosa|\n|         4.5|        2.3|         1.3|        0.3|    Iris-setosa|\n|         5.5|        2.3|         4.0|        1.3|Iris-versicolor|\n|         6.5|        2.8|         4.6|        1.5|Iris-versicolor|\n|         5.5|        2.4|         3.8|        1.1|Iris-versicolor|\n|         5.5|        2.4|         3.7|        1.0|Iris-versicolor|\n|         5.5|        2.5|         4.0|        1.3|Iris-versicolor|\n|         5.5|        2.6|         4.4|        1.2|Iris-versicolor|\n|         6.5|        3.0|         5.8|        2.2| Iris-virginica|\n|         6.5|        3.2|         5.1|        2.0| Iris-virginica|\n|         6.5|        3.0|         5.5|        1.8| Iris-virginica|\n|         6.5|        3.0|         5.2|        2.0| Iris-virginica|\n+------------+-----------+------------+-----------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Using endswith\n",
    "new_onlinedata_df.filter(new_onlinedata_df.sepal_length.endswith(\"5\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ec12bd8-d8dc-4623-b296-f8cb0f3c27d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n|sepal_length|sepal_width|petal_length|petal_width|    species|\n+------------+-----------+------------+-----------+-----------+\n|         5.8|        4.0|         1.2|        0.2|Iris-setosa|\n+------------+-----------+------------+-----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#contains\n",
    "new_onlinedata_df.filter(new_onlinedata_df.sepal_width.contains(\"4.0\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30dc7025-6468-4258-a8e3-920a17fe6e19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+---------------+\n|sepal_length|sepal_width|petal_length|petal_width|        species|\n+------------+-----------+------------+-----------+---------------+\n|         4.7|        3.2|         1.3|        0.2|    Iris-setosa|\n|         4.4|        2.9|         1.4|        0.2|    Iris-setosa|\n|         4.7|        3.2|         1.6|        0.2|    Iris-setosa|\n|         5.5|        4.2|         1.4|        0.2|    Iris-setosa|\n|         5.0|        3.2|         1.2|        0.2|    Iris-setosa|\n|         4.5|        2.3|         1.3|        0.3|    Iris-setosa|\n|         4.4|        3.2|         1.3|        0.2|    Iris-setosa|\n|         4.6|        3.2|         1.4|        0.2|    Iris-setosa|\n|         7.0|        3.2|         4.7|        1.4|Iris-versicolor|\n|         6.4|        3.2|         4.5|        1.5|Iris-versicolor|\n|         5.5|        2.3|         4.0|        1.3|Iris-versicolor|\n|         6.5|        2.8|         4.6|        1.5|Iris-versicolor|\n|         5.7|        2.8|         4.5|        1.3|Iris-versicolor|\n|         4.9|        2.4|         3.3|        1.0|Iris-versicolor|\n|         6.6|        2.9|         4.6|        1.3|Iris-versicolor|\n|         5.2|        2.7|         3.9|        1.4|Iris-versicolor|\n|         5.0|        2.0|         3.5|        1.0|Iris-versicolor|\n|         6.0|        2.2|         4.0|        1.0|Iris-versicolor|\n|         6.1|        2.9|         4.7|        1.4|Iris-versicolor|\n|         5.6|        2.9|         3.6|        1.3|Iris-versicolor|\n+------------+-----------+------------+-----------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# like - SQL LIKE pattern\n",
    "new_onlinedata_df.filter(new_onlinedata_df.sepal_width.like(\"%2%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76ba650b-276c-4a16-bf79-ccea934cf9f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n|sepal_length|sepal_width|petal_length|petal_width|species|\n+------------+-----------+------------+-----------+-------+\n+------------+-----------+------------+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# rlike - SQL RLIKE pattern (LIKE with Regex)\n",
    "new_onlinedata_df.filter(new_onlinedata_df.sepal_width.rlike(\"^[0-9]*$\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "815ebc32-9f65-476f-ad47-b0a375af3f7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n|sepal_length|sepal_width|petal_length|petal_width|    species|\n+------------+-----------+------------+-----------+-----------+\n|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n|         5.4|        3.9|         1.7|        0.4|Iris-setosa|\n|         4.6|        3.4|         1.4|        0.3|Iris-setosa|\n|         5.0|        3.4|         1.5|        0.2|Iris-setosa|\n|         4.4|        2.9|         1.4|        0.2|Iris-setosa|\n|         4.9|        3.1|         1.5|        0.1|Iris-setosa|\n|         5.4|        3.7|         1.5|        0.2|Iris-setosa|\n|         4.8|        3.4|         1.6|        0.2|Iris-setosa|\n|         4.8|        3.0|         1.4|        0.1|Iris-setosa|\n|         4.3|        3.0|         1.1|        0.1|Iris-setosa|\n|         5.8|        4.0|         1.2|        0.2|Iris-setosa|\n|         5.7|        4.4|         1.5|        0.4|Iris-setosa|\n|         5.4|        3.9|         1.3|        0.4|Iris-setosa|\n|         5.1|        3.5|         1.4|        0.3|Iris-setosa|\n|         5.7|        3.8|         1.7|        0.3|Iris-setosa|\n|         5.1|        3.8|         1.5|        0.3|Iris-setosa|\n|         5.4|        3.4|         1.7|        0.2|Iris-setosa|\n+------------+-----------+------------+-----------+-----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "new_onlinedata_df.filter(regexp_extract(col(\"sepal_length\"), r\"\\d+\", 0) != \"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2431a67a-550e-414d-898c-613686a6eaf7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n|sepal_length|sepal_width|petal_length|petal_width|species|\n+------------+-----------+------------+-----------+-------+\n+------------+-----------+------------+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "new_onlinedata_df.filter(regexp_extract(col(\"species\"), r\"\\d+\", 0) != \"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b9bc17a-ec64-4532-be00-a4573db20b26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[211]: True"
     ]
    }
   ],
   "source": [
    "#check species column in list\n",
    "listColumns=new_onlinedata_df.columns \n",
    "\"species\" in listColumns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87760e73-dcc1-4fbc-8a7c-79163bc9036c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n|employee_name|department|state|salary|age|bonus|\n+-------------+----------+-----+------+---+-----+\n|        James|     Sales|   NY| 90000| 34|10000|\n|      Michael|     Sales|   NY| 86000| 56|20000|\n|       Robert|     Sales|   CA| 81000| 30|23000|\n|        Maria|   Finance|   CA| 90000| 24|23000|\n|        Raman|   Finance|   CA| 99000| 40|24000|\n|        Scott|   Finance|   NY| 83000| 36|19000|\n|          Jen|   Finance|   NY| 79000| 53|15000|\n|         Jeff| Marketing|   CA| 80000| 25|18000|\n|        Kumar| Marketing|   NY| 91000| 50|21000|\n+-------------+----------+-----+------+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000),\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Raman\",\"Finance\",\"CA\",99000,40,24000),\n",
    "    (\"Scott\",\"Finance\",\"NY\",83000,36,19000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "schema = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "simple_df = spark.createDataFrame(simpleData,  schema)\n",
    "simple_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880410eb-6c8a-4d7e-a2a8-92a7f23e8ca0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+-------+-----+------+-----+\n|department|James| Jeff|  Jen|Kumar|Maria|Michael|Raman|Robert|Scott|\n+----------+-----+-----+-----+-----+-----+-------+-----+------+-----+\n|     Sales|90000| null| null| null| null|  86000| null| 81000| null|\n|   Finance| null| null|79000| null|90000|   null|99000|  null|83000|\n| Marketing| null|80000| null|91000| null|   null| null|  null| null|\n+----------+-----+-----+-----+-----+-----+-------+-----+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,sum,avg, collect_list\n",
    "dep_sal =simple_df.groupBy(\"department\") \\\n",
    "           .pivot(\"employee_name\") \\\n",
    "           .agg(sum(\"salary\").alias(\"sum_salary\"))\n",
    "dep_sal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b3660f9-1eb9-4ce5-82c9-5a777c70e61f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------+\n|department|      employee_names|total_salary|\n+----------+--------------------+------------+\n|     Sales|[James, Michael, ...|      257000|\n|   Finance|[Maria, Raman, Sc...|      351000|\n| Marketing|       [Jeff, Kumar]|      171000|\n+----------+--------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "deptSalaryDF = simple_df.groupBy(\"department\") \\\n",
    "                         .agg(collect_list(\"employee_name\").alias(\"employee_names\"), \n",
    "                          sum(\"salary\").alias(\"total_salary\"))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "deptSalaryDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f32da8c-155f-4cf8-a9b0-3f4df6d15fc5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+\n|department|employee_name|sum_salary|\n+----------+-------------+----------+\n|     Sales|      Michael|     86000|\n|     Sales|        James|     90000|\n|   Finance|        Maria|     90000|\n|     Sales|       Robert|     81000|\n|   Finance|        Raman|     99000|\n|   Finance|        Scott|     83000|\n| Marketing|         Jeff|     80000|\n|   Finance|          Jen|     79000|\n| Marketing|        Kumar|     91000|\n+----------+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "dff = simple_df.groupBy(\"department\",\"employee_name\") \\\n",
    "    .agg(sum(\"salary\").alias(\"sum_salary\"))\n",
    "dff.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376de0ef-ce3d-4b49-ae30-c9dd3f692401",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# assuming you have a DataFrame called \"employees\" with columns \"employee_name\", \"department\", and \"salary\"\n",
    "\n",
    "result = simple_df.groupBy(\"department\", \"employee_name\").agg(sum(\"salary\").alias(\"total_salary\")).orderBy(\"department\", \"total_salary\", ascending=[True, False])\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "deeec297-1735-4023-bc4d-9cbd92e480e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "day6-pyspark",
   "notebookOrigID": 2521248266669698,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
