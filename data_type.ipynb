{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b24d2c2-a8e4-46ad-b14c-fb9e9baf181f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>name</th><th>middele name</th><th>last name</th><th>age</th><th>gender</th><th>salary</th></tr></thead><tbody><tr><td>James</td><td></td><td>Smith</td><td>36636</td><td>M</td><td>3000</td></tr><tr><td>Michael</td><td>Rose</td><td></td><td>40288</td><td>M</td><td>4000</td></tr><tr><td>Robert</td><td></td><td>Williams</td><td>42114</td><td>M</td><td>4000</td></tr><tr><td>Maria</td><td>Anne</td><td>Jones</td><td>39192</td><td>F</td><td>4000</td></tr><tr><td>Jen</td><td>Mary</td><td>Brown</td><td></td><td>F</td><td>-1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "James",
         "",
         "Smith",
         "36636",
         "M",
         3000
        ],
        [
         "Michael",
         "Rose",
         "",
         "40288",
         "M",
         4000
        ],
        [
         "Robert",
         "",
         "Williams",
         "42114",
         "M",
         4000
        ],
        [
         "Maria",
         "Anne",
         "Jones",
         "39192",
         "F",
         4000
        ],
        [
         "Jen",
         "Mary",
         "Brown",
         "",
         "F",
         -1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "middele name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "last name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "salary",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession object\n",
    "spark = SparkSession.builder.appName(\"create_df_with_datatype\").getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
    "    (\"Michael\",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
    "    (\"Robert\",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
    "    (\"Maria\",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
    "    (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)\n",
    "  ]\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"middele name\", StringType(), True),\n",
    "    StructField(\"last name\", StringType(), True),\n",
    "    StructField(\"age\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "df = spark.createDataFrame(data, schema)        \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74d2f7d-37e9-4492-849f-14968c473b25",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: [('name', 'string'),\n ('middele name', 'string'),\n ('last name', 'string'),\n ('age', 'string'),\n ('gender', 'string'),\n ('salary', 'int')]"
     ]
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "418e53cf-9694-4a3c-a6e3-f60d3dcb7440",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: [('Id', 'int'),\n ('SepalLengthCm', 'double'),\n ('SepalWidthCm', 'double'),\n ('PetalLengthCm', 'double'),\n ('PetalWidthCm', 'double'),\n ('Species', 'string')]"
     ]
    }
   ],
   "source": [
    "#Read csv file\n",
    "iris_df = spark.read.csv(\"/FileStore/tables/Iris.csv\", header=True, inferSchema=True)\n",
    "# check datatype of csv column\n",
    "iris_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0396bcd3-05a8-41ab-b454-062881c4fbde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: [('Id', 'int'),\n ('SepalLengthCm', 'int'),\n ('SepalWidthCm', 'string'),\n ('PetalLengthCm', 'string'),\n ('PetalWidthCm', 'string'),\n ('Species', 'string')]"
     ]
    }
   ],
   "source": [
    "#Structtype is collection of structfield used to define the structure of the DataFrame\n",
    "#StructField is used to define the column name, data type, and a flag for nullable or not\n",
    "#Pass new schema and change the datatype of csv column\n",
    "new_schema = StructType([\n",
    "    StructField(\"Id\", IntegerType(), True),\n",
    "    StructField(\"SepalLengthCm\", IntegerType(), True),\n",
    "    StructField(\"SepalWidthCm\", StringType(), True),\n",
    "    StructField(\"PetalLengthCm\", StringType(), False),\n",
    "    StructField(\"PetalWidthCm\", StringType(), True),\n",
    "    StructField(\"Species\", StringType(), True),\n",
    "   \n",
    "])\n",
    "iris_df1 = spark.read.csv(\"/FileStore/tables/Iris.csv\", header=True, schema=new_schema)\n",
    "iris_df1.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aab05c12-d3e6-44ad-9e0e-2a46bd6f001a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Id: integer (nullable = true)\n |-- SepalLengthCm: integer (nullable = true)\n |-- SepalWidthCm: string (nullable = true)\n |-- PetalLengthCm: string (nullable = true)\n |-- PetalWidthCm: string (nullable = true)\n |-- Species: string (nullable = true)\n\nroot\n |-- Id: integer (nullable = true)\n |-- SepalLengthCm: integer (nullable = true)\n |-- SepalWidthCm: string (nullable = true)\n |-- PetalLengthCm: string (nullable = false)\n |-- PetalWidthCm: string (nullable = true)\n |-- Species: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "iris_df1.printSchema()\n",
    "iris_df2 = spark.createDataFrame(iris_df1.rdd, new_schema)\n",
    "iris_df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "655a2bd6-e661-47ea-ad7c-341e2f0f8cb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- name: struct (nullable = true)\n |    |-- first_name: string (nullable = true)\n |    |-- middle_name: string (nullable = true)\n |    |-- last_name: string (nullable = true)\n |-- id: string (nullable = true)\n |-- gender: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n+--------------------+-----+------+------+\n|                name|   id|gender|salary|\n+--------------------+-----+------+------+\n|    {James, , Smith}|36636|     M|  3100|\n|   {Michael, Rose, }|40288|     M|  4300|\n|{Robert, , Williams}|42114|     M|  1400|\n|{Maria, Anne, Jones}|39192|     F|  5500|\n|  {Jen, Mary, Brown}|     |     F|    -1|\n+--------------------+-----+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "#Column Name \"name\" consist of nested columns firstname, middlename, lastname\n",
    "data1 = [((\"James\", \"\", \"Smith\"), \"36636\", \"M\", 3100),\n",
    "        ((\"Michael\", \"Rose\", \"\"), \"40288\", \"M\", 4300),\n",
    "        ((\"Robert\", \"\", \"Williams\"), \"42114\", \"M\", 1400),\n",
    "        ((\"Maria\", \"Anne\", \"Jones\"), \"39192\", \"F\", 5500),\n",
    "        ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"F\", -1)]\n",
    "schema1= StructType([\n",
    "    StructField(\"name\", StructType([\n",
    "        StructField(\"first_name\", StringType(), True),\n",
    "        StructField(\"middle_name\", StringType(), True),\n",
    "        StructField(\"last_name\", StringType(), True)\n",
    "    ])),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)  \n",
    "    ])\n",
    "\n",
    "df2 = spark.createDataFrame(data1, schema1)\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead71c54-5ec8-4e7c-8008-0c390f42cf02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_type",
   "notebookOrigID": 738265764730268,
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
